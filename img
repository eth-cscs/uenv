#!/usr/bin/env python3

# for handling http requests with the middleware
import argparse
from datetime import datetime, timezone
from enum import Enum
import fcntl
import json
import os
import requests
import subprocess
import sys

UENV_CLI_API_VERSION=1

# Choose whether to use colored output.
# - by default colored output is ON
# - if the flag --no-color is passed it is OFF
# - if the environment variable NO_COLOR is set it is OFF
def use_colored_output(cli_arg):
    # The --no-color argument overrides all environment variables if passed.
    if cli_arg:
        return False

    # Check the env. var NO_COLOR and disable color if set.
    if os.environ.get('NO_COLOR') is not None:
        color_var = os.environ.get('NO_COLOR')
        if len(color_var)>0 and color_var != "0":
            return False

    return True

def colorize(string, color):
    colors = {
        "red":     "31",
        "green":   "32",
        "yellow":  "33",
        "blue":    "34",
        "magenta": "35",
        "cyan":    "36",
        "white":   "37",
    }
    if colored_output:
        return f"\033[1;{colors[color]}m{string}\033[0m"
    else:
        return string

def print_error_and_exit(message):
    print(f"{colorize('error', 'red')} {message}", file=sys.stderr)
    exit(1)

def exit_with_success():
    exit(0)

def make_argparser():
    parser = argparse.ArgumentParser(description=("Interact with the uenv artifactory"))
    parser.add_argument("--no-color", action="store_true",
            help="disable color output")
    parser.add_argument("--build", action="store_true",
            help="enable undeployed builds",
            required=False)

    subparsers = parser.add_subparsers(dest="command")

    find_parser = subparsers.add_parser("find", help="find uenv in the CSCS registry")
    find_parser.add_argument("-s", "--system", required=False, type=str)
    find_parser.add_argument("-a", "--uarch", required=False, type=str)
    find_parser.add_argument("uenv", nargs="?", default=None, type=str)

    pull_parser = subparsers.add_parser("pull", help="pull a uenv from the CSCS registry")
    pull_parser.add_argument("-s", "--system", required=False, type=str)
    pull_parser.add_argument("-a", "--uarch", required=False, type=str)
    pull_parser.add_argument("uenv", nargs="?", default=None, type=str)

    pull_parser = subparsers.add_parser("list", help="list cached images")
    pull_parser.add_argument("-s", "--system", required=False, type=str)
    pull_parser.add_argument("-a", "--uarch", required=False, type=str)
    pull_parser.add_argument("uenv", nargs="?", default=None, type=str)

    return parser

def get_options(args):
    options = {}
    if args.system is None:
        sys_name = os.getenv("CLUSTER_NAME")
        if sys_name is None:
            raise ValueError("No system name was provided, and the CLUSTER_NAME environment variable is not set.")
        options["system"] = sys_name
    else:
        options["system"] = args.system

    options["name"] = args.uenv
    options["uarch"] = args.uarch

    options["repo"] = "deploy" if not args.build else "build"
    return options


def get_filter(args):
    options = get_options(args)
    img_filter = {"system": options["system"]}

    for key, value in parse_uenv_string(options["name"]).items():
        if value is not None:
            img_filter[key] = value

    if options["uarch"] is not None:
        img_filter["uarch"] = options["uarch"]
    repo = options["repo"]

    return repo, img_filter

class LockType(Enum):
    READ = 1
    WRITE = 2

class Lock():
    def __init__(self, path: str, type: LockType):
        self._lockfile = f"{path}.lock"

        # open the file
        self._lock = open(self._lockfile, "a")

        # acquire lock
        self._type = type
        if self._type==LockType.READ:
            # acquire shared lock
            fcntl.flock(self._lock, fcntl.LOCK_SH)
        else:
            # acquire exclusive lock
            fcntl.flock(self._lock, fcntl.LOCK_EX)

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_value, exc_traceback):
        fcntl.flock(self._lock, fcntl.LOCK_UN)  # Release the lock
        self._lock.close()


class Record:

    def __init__(self, system: str, uarch: str, name: str, version: str, tag: str, date: str, size_bytes: int, sha256: str):
        self._system  = system
        self._uarch   = uarch
        self._name    = name
        self._version = version
        self._tag     = tag
        self._date    = date
        self._bytes   = size_bytes
        self._sha256  = sha256

    # build/eiger/zen2/cp2k/2023/1133706947
    @classmethod
    def frompath(cls, path: str, date: str, size_bytes: int, sha256: str):
        fields = path.split("/")
        if len(fields) != 5:
            raise ValueError("Record must have exactly 5 fields")

        system, uarch, name, version, tag = fields
        return cls(system, uarch, name, version, tag, date, size_bytes, sha256)

    @classmethod
    def fromjson(cls, raw: dict):
        print(raw)
        system = raw["system"]
        uarch = raw["uarch"]
        name = raw["name"]
        version = raw["version"]
        tag = raw["tag"]
        date = raw["date"]
        size_bytes = raw["size_bytes"]
        sha256 = raw["sha256"]

        return cls(system, uarch, name, version, tag, date, size_bytes, sha256)

    def __eq__(self, other):
        if not isinstance(other, Record):
            return False
        return self.sha256==other.sha256

    def __lt__(self, other):
        if self.system  < other.system: return True
        if other.system < self.system: return False
        if self.uarch   < other.uarch: return True
        if other.uarch  < self.uarch: return False
        if self.name    < other.name: return True
        if other.name   < self.name: return False
        if self.version < other.version: return True
        if other.version< self.version: return False
        if self.tag     < other.tag: return True
        #if other.tag    < self.tag: return False
        return False

    def __str__(self):
        return f"{self.name}/{self.version}:{self.tag} @ {self.system}:{self.uarch}"

    def __repr__(self):
        return f"Record({self.system}, {self.uarch}, {self.name}, {self.version}, {self.tag})"

    @property
    def system(self):
        return self._system

    @property
    def uarch(self):
        return self._uarch

    @property
    def name(self):
        return self._name

    @property
    def date(self):
        return self._date

    @property
    def version(self):
        return self._version

    @property
    def tag(self):
        return self._tag

    @property
    def sha256(self):
        return self._sha256

    @property
    def size(self):
        return self._bytes

    @property
    def datestring(self):
        return self.date.strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + 'Z'

    @property
    def path(self):
        return f"{self.system}/{self.uarch}/{self.name}{self.version}/{self.tag}"

    @property
    def dictionary(self):
        return {
                "system": self.system,
                "uarch": self.uarch,
                "name": self.name,
                "date": self.datestring,
                "version": self.version,
                "tag": self.tag,
                "sha256": self.sha256,
                "size": self.size
               }

def relative_path_from_record(record):
    return f"{record.sha256}"

def relative_jfrog_from_record(record):
    return f"{record.system}/{record.uarch}/{record.name}/{record.version}:{record.tag}"

# pretty print a list of Record
def print_records(records):
    if len(records)>0:
        print(colorize(f"{'uenv/version:tag':40}{'uarch':6}{'date':10} {'sha256':16} {'size':<10}", "yellow"))
        for r in records:
            namestr = f"{r.name}/{r.version}"
            tagstr = f"{r.tag}"
            label = namestr + ":" + tagstr
            datestr = r.date.strftime("%Y-%m-%d")
            S = r.size
            if S<1024:
                size_str = f"{S:<} bytes"
            elif S<1024*1024:
                size_str = f"{(S/1024):<.0f} kB"
            elif S<1024*1024*1024:
                size_str = f"{(S/(1024*1024)):<.0f} MB"
            else:
                size_str = f"{(S/(1024*1024*1024)):<.1f} GB"
            print(f"{label:<40}{r.uarch:6}{datestr:10} {r.sha256[:16]:16} {size_str:<10}")

class DataStore:
    def __init__(self):
        # all images store with (key,value) = (sha256,Record)
        self.images = {}

        self.store = {"system": {}, "uarch": {}, "name": {}, "version": {}, "tag": {}}

    def add_record(self, r: Record, overwrite: bool = False):
        # test for collisions
        if (not overwrite) and (self.images.get(r.sha256, None) is not None):
            raise ValueError(f"an image with the hash {r.sha256} already exists")

        sha = r.sha256
        self.images[sha] = r
        self.store["system"] .setdefault(r.system, []).append(sha)
        self.store["uarch"]  .setdefault(r.uarch, []).append(sha)
        self.store["name"]   .setdefault(r.name, []).append(sha)
        self.store["version"].setdefault(r.version, []).append(sha)
        self.store["tag"]    .setdefault(r.tag, []).append(sha)

    def find_records(self, **constraints):
        if not constraints:
            raise ValueError("At least one constraint must be provided")

        for field in constraints:
            if field not in self.store:
                raise ValueError(f"Invalid field: {field}. Must be one of 'system', 'uarch', 'name', 'version', 'tag'")

        # Find matching records for each constraint
        matching_records_sets = [
            set(self.store[field].get(value, [])) for field, value in constraints.items()
        ]

        # Intersect all sets of matching records
        if matching_records_sets:
            unique = set.intersection(*matching_records_sets)
        else:
            unique = set()

        results = [self.images[sha] for sha in unique]
        results.sort(reverse=True)
        return results

    def get_record(self, sha256: str) -> Record:
        return self.images.get(sha256, None)

    # Convert to a dictionary that can be written to file as JSON
    # The serialisation and deserialisation are central: able to represent
    # uenv that are available in both JFrog and filesystem directory tree.
    def serialise(self, version: int=UENV_CLI_API_VERSION):
        return {
                "API_VERSION": version,
                "images": [img.dictionary for img in self.images.values()]
        }

    # Convert to a dictionary that can be written to file as JSON
    # The serialisation and deserialisation are central: able to represent
    # uenv that are available in both JFrog and filesystem directory tree.
    @classmethod
    def deserialise(cls, datastore):
        result = cls()
        for img in datastore["images"]:
            result.add_record(Record.from_dictionary(img))

class FileSystemCache():
    def __init__(self, path: str, create: bool=False):
        self._path = path
        self._index = path + "/index.json"

        if not os.path.exists(self._index):
            # error: cache does not exists
            raise FileNotFoundError(f"filesystem cache not found {self._path}")

        with open(self._index, "r") as fid:
            raw = json.loads(fid.read())
            self._database = DataStore()
            for img in raw["images"]:
                self._database.add_record(Record(img))

    @staticmethod
    def create_if_missing(path: str):
        if not os.path.exists(path):
            # LOG: f"FileSyStemCache: creating path {path}"
            os.makedirs(path)
        index_file = f"{path}/index.json"
        if not os.path.exists(index_file):
            # LOG: f"FileSyStemCache: creating empty index {index_file}"
            empty_config = { "API_VERSION": UENV_CLI_API_VERSION, "images": [] }
            with open(index_file, "w") as f:
                # default serialisation is str to serialise the pathlib.PosixPath
                f.write(json.dumps(empty_config, sort_keys=True, indent=2, default=str))
                f.write("\n")

        # LOG: f"FileSyStemCache: available {index_file}"

    @property
    def database(self):
        return self._database

    def add_record(self, record: Record):
        self._database.add_record(record)

    # The path where an image would be stored
    # will return a path even for images that are not stored
    def image_path(self, r: Record) -> str:
        return self._path + "/images/" + r.path

    # Return the full record for a given hash
    # Returns None if no image with that hash is stored in the repo.
    def get_record(self, sha256: str):
        return self._database.get_record(sha256)

    def publish(self):
        with open(self._index, "w") as f:
            # default serialisation is str to serialise the pathlib.PosixPath
            f.write(json.dumps(self._database.serialise(), sort_keys=True, indent=2, default=str))
            f.write("\n")

# The https://cicd-ext-mw.cscs.ch/uenv/list API endpoint returns
# a list of images in the jfrog uenv.
#
#{
#  "results":
#  [
#    {
#      "repo" : "uenv",
#      "path" : "build/clariden/zen3/prgenv-gnu/23.11/1094139948",
#      "name" : "manifest.json",
#      "created" : "2023-12-04T09:05:44.034Z",
#      "size" : "123683707",
#      "sha256" : "134c04d01bb3583726804a094b144d3637997877ef6162d1fe19eabff3c72c3a",
#      "stats" : [{
#        "downloaded" : "2023-12-11T17:56:59.052Z",
#        "downloads" : 11
#      }]
#    },
#    ...
#  ],
#  "range" :
#  {
#    "start_pos" : 0,
#    "end_pos" : 22,
#    "total" : 22
#  }
#}
#

def query_jfrog() -> tuple:
    try:
        # GET request to the middleware
        url = "https://cicd-ext-mw.cscs.ch/uenv/list"
        response = requests.get(url)
        response.raise_for_status()

        raw_records = response.json()

        deploy_database = DataStore()
        build_database = DataStore()

        for record in raw_records["results"]:
            path = record["path"]

            date = to_datetime(record["created"])
            sha256 = record["sha256"]
            size = record["size"]
            if path.startswith("build/"):
                r = Record.frompath(path[len("build/"):], date, size, sha256)
                build_database.add_record(r)
            if path.startswith("deploy/"):
                r = Record.frompath(path[len("deploy/"):], date, size, sha256)
                deploy_database.add_record(r)


        return (deploy_database, build_database)

    except Exception as error:
        raise RuntimeError("unable to access the JFrog uenv API.")

def to_datetime(date: str):
    # In Python 3.6, datetime.fromisoformat is not available.
    # Manually parsing the string.
    dt_format = '%Y-%m-%dT%H:%M:%S.%fZ'
    return datetime.strptime(date, dt_format).replace(tzinfo=timezone.utc)

# return dictionary {"name", "version", "tag"} from a uenv description string
#       "prgenv_gnu"              -> ("prgenv_gnu", None, None)
#       "prgenv_gnu/23.11"        -> ("prgenv_gnu", "23.11", None)
#       "prgenv_gnu/23.11:latest" -> ("prgenv_gnu", "23.11", "latest")
def parse_uenv_string(desc: str) -> dict:
    name = version = tag = None

    if desc:
        splits = desc.split("/",1)
        name = splits[0]
        if len(splits)>1:
            splits = splits[1].split(":",1)
            version = splits[0]
            tag = splits[1] if len(splits)>1 else None

    return {"name": name, "version": version, "tag": tag}

def run_oras_command(args):
    try:
        command = ['oras'] + args

        #print(f"{colorize('running oras', 'yellow')}: {' '.join(command)}")

        result = subprocess.run(
            command,
            stdout=subprocess.PIPE,  # Capture standard output
            stderr=subprocess.PIPE,  # Capture standard error
            check=True,  # Raise exception if command fails
            encoding='utf-8'  # Decode output from bytes to string
        )

        # Print standard output
        print("Output:\n", result.stdout)

    except subprocess.CalledProcessError as e:
        # Print error message along with captured standard error
        print("An error occurred:\n", e.stderr)

# the path used to store a users cached images and meta data
def uenv_repo_path():
    # check whether the image path has been explicitly set:
    path = os.environ.get('UENV_IMAGE_PATH')
    if path is not None:
        return path

    # if not, try to use the path $SCRATCH/.uenv-images/, if SCRATCH exists
    path = os.environ.get('SCRATCH')
    if path is not None:
        return path

    return None

# return the relative path of an image
def record_path(record):
    return f"{record.system}/{record.uarch}/{record.name}/{record.version}/{record.tag}"

# the path of the image corresponding to a specific image in the user cache
def uenv_record_path(record):
    store = uenv_image_path()
    if store:
        return store + "/images/" + relative_path_from_record(record)
    return store

if __name__ == "__main__":
    parser = make_argparser()
    args = parser.parse_args()
    if args.command is None:
        parser.print_help()
        sys.exit()

    global colored_output
    colored_output = use_colored_output(args.no_color)

    if args.command in ["find", "pull"]:
        deploy, build = query_jfrog()
        #print(deploy.serialise())
        #print(build.serialise())
        database = {"build": build, "deploy": deploy}

        repo, img_filter = get_filter(args)
        records = database[repo].find_records(**img_filter)

        if args.command == "find":
            print_records(records)

            # verify that there is at least one image that matches the query
            if len(records)==0:
                print("no images match the query")

            exit_with_success()

        if args.command == "pull":
            # verify that there is at least one image that matches the query
            if len(records)==0:
                print_error_and_exit(f"no images match the query {args.uenv}")

            # check that there is only one uenv name
            if len(set([r.name for r in records]))>1:
                print_records(records)
                print()
                print_error_and_exit(f"ambiguous uenv {args.uenv}")

            # check that there is only one uenv name
            if len(set([r.uarch for r in records]))>1:
                print_records(records)
                print()
                print_error_and_exit(
                        "more than one uarch matches the the requested uenv. "
                        "Specify the desired uarch with the --uarch flag")

            base = f"jfrog.svc.cscs.ch/uenv/{repo}"
            t = records[0]
            jfrog_address = f"{base}/{relative_jfrog_from_record(t)}"

            print(f"{t} from {jfrog_address} {t.size/(1024*1024):.0f} MB")

            repo_path = uenv_repo_path()
            with Lock(f"{repo_path}/index.json", LockType.READ) as lk:
                cache = FileSystemCache(repo_path)
                print(cache.database)
                print(f"{t.dictionary}")

                base_path = cache.image_path(t)
                image_path = base_path + "/store.squashfs"
                print(f"{base_path}")
                print(f"{image_path}")

                # if the record isn't already in the filesystem repo download it
                if cache.get_record(t.sha256) is None:
                    print(f"  downloading {t.sha256}")
                    run_oras_command(["pull", "-o", base_path, jfrog_address])
                print(f"  ... available at {path}/store.squashfs")

            #else:
                #print_error_and_exit("set UENV_IMAGE_PATH to specify where uenv images should be stored")

            exit_with_success()

    if args.command == "list":
        repo_path = uenv_repo_path()
        print(f"repo  {colorize(repo_path, 'yellow')}")
        #cache = FileSystemCache(repo_path, create=True)
        #print(cache.database)

        try:
            FileSystemCache.create_if_missing(repo_path)
        except Exception as err:
            print_error_and_exit(f"unable to find or initialise the local registry: {str(err)}")

        with Lock(f"{repo_path}/index.json", LockType.READ) as lk:
            fscache = FileSystemCache(repo_path)
            print(fscache.database)

